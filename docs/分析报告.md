## “数据分析” 关键分析企业需要什么养的数据分析人才

### 问题背景

此次分析是启发于临近实验室研究生博士生学长学姐求职季，抱着证实R语言这款工具的想法。希望借此作业了解企业对相关职位的需求，针对猎聘网、拉勾网等招聘网站的相关岗位招聘数据的爬取、分析及挖掘时间，锻炼自己所学知识解决生活中的实际问题，以期为将来求职提供一定的数据支持

### 目的

1. 了解企业对物流工程、供应链管理、人工智能、数据挖掘等相关人才的需求情况，以及应该具备的能力和素质
2. 分析结果为自己今后的学习和求职提供指导。

### 分析问题

1. 不同地区，数据分析岗位的需求分布以及对应的薪资分布
2. 不同经验，数据分析岗位的需求分布以及对应的薪资分布
3. 不同学历，数据分析岗位的需求分布以及对应的薪资分布
4. 不同企业规模，数据分析岗位的需求分布以及对应的薪资分布
5. 探索数据分析岗位对应的工具型技能与对应的薪资水平
6. 探索数据分析岗位对应非工具型能力的需求

### 数据集字段

| 类型          | 中文字段名     | 备注                                   |
| ------------- | -------------- | -------------------------------------- |
| int           | 主键           | 与数据库表主键功能类似，用于处理表关联 |
| varchar2(50)  | 岗位名称       |                                        |
| varchar2(50)  | 公司名称       | 用于招聘企业词云分析                   |
| varchar2(50)  | 年薪W          | 用于分析平均年薪                       |
| varchar2(50)  | 工作地点       | 用于分析地域                           |
| varchar2(50)  | 学历要求       | 用于分析职位对学历的要求               |
| varchar2(50） | 职位对经验要求 | 分析工作经验的影响                     |
|               |                |                                        |
|               |                |                                        |

数据获取：

- 来源：猎聘网、拉勾网
- 数据样本量：4500条
- 工具：R爬虫  rvest包
- 时间：所有数据截至2019年3月28日

### 数据爬虫

#### 思路

- 第一步确定要爬取的内容
- 第二步爬取当前页数据（核心）
- 第三步循环爬取所有页

revestLiepin.R

```
library(rvest)
library(dplyr)
library(stringr)
library(xml2)
library(readr)
library(tidyverse)

setwd("E:/Rcase/practices")
#首先，构建仅爬取一页的Function:
crawl_one_page <- function(key, i) {
  #key 为爬取岗位关键词， i 为页码
  base_url <- "https://www.liepin.com/zhaopin/?&fromSearchBtn=2"
  key <- iconv(key, to = "UTF-8") # 保证关键词文本为UTF-8编码
  #构建URL并加码。注意：别忘了curPage是从0开始的。
  liepin_url <- str_c(base_url, "&key=", key, "&curPage=", (i-1)) %>% URLencode()
  #由于网站信息可能随时更新，所以下载网页方便验证数据准确性。
  #构建文件路径，绝对路径
  file_name <- "E:/Rcase/practices/html/scrapepage.html" 
  download_html(liepin_url, file_name) 
  #下面就是真正从网页上抓取数据了
  lp_html <- read_html(file_name)
  position <- lp_html %>%     #岗位名称
    html_nodes(".job-info h3 a") %>%
    html_text() %>%
    str_trim() #删除多余的空白
  company <- lp_html %>%      #公司名称
    html_nodes(".company-name a") %>%
    html_text()
  #岗位要求，例如：12-18万_北京_大专及以上_5年以上
  req_info <- lp_html %>%     
    html_nodes(".condition") %>%
    html_attr("title") #get title attribute
  req_tb<- str_split(req_info, "_", simplify = TRUE) %>% as_tibble()
  ##req_tb<- str_split(req_info, "_", simplify = TRUE) %>% as.data.frame() %>% t()

  colnames(req_tb) <- c('salary', 'city', 'education', 'experience')
  pos_tb <- tibble(position, company) %>% bind_cols(req_tb)
  print(pos_tb)
  pos_tb <- pos_tb[which(pos_tb$salary != "面议" ),]

  pos_tb$salary <- sub('万', '', pos_tb$salary) %>% strsplit('-') %>%
    lapply(function(x){as.numeric(x) %>% mean()}) %>% unlist()
  return(pos_tb)
}

#之后，构建爬取n个网页的function：
crawl_n_page <- function(key, n){
  print("Hello World!!!")
  pos_lt <- vector("list", n)
  for (i in seq_len(n)) {
    pos_lt[[i]] <- crawl_one_page(key, i) 
    cat("Crawling page:", i, "\tProgress:", (i/n)*100, "%\n") #显示进度
    Sys.sleep(1)
  }
  pos_tb <- bind_rows(pos_lt) #将list转换为tibble
  return(pos_tb)
}

#爬取10页数据分析岗位招聘信息
position <- "人工智能"
#首先尝试爬取1页是否成功： pos_tb <- crawl_one_page(position, 4)
#然后爬取10页内容
pos_tb <- crawl_n_page(position, 100)

write.csv(pos_tb,file="E:/Rcase/practices/data/ai_info032801.csv")
```



### 数据分析

```
library(ggplot2)
library(plyr)
library(wordcloud2)
attach(dataAnaly_info)
```

#### 问题一：不同地区，数据分析岗位的需求分布以及对应的薪资分布

数据分析岗位需求量最大的城市北京、杭州、上海 占了前三甲。其中仅仅北京酒占据了一半。北上广深杭州占据近90%的需求量。数据分析师的平均月薪为19k，月薪的分布主要集中在10k-25k

![1553912937754](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553912937754.png)

代码如下：

```

# 数据加载
# 选择对应数据集
AI.df <- read.csv(file.choose())
str(AI.df)
#VIM包的aggr函数来识别
#问题1：不同地区，数据分析岗位的需求分布以及对应的薪资分布
aggr(AI.df,prop=TRUE,numbers=TRUE)
city.table <- data.frame(prop.table(table(reorder_size(city,TRUE))))
city.table <- city.table[c(1:15),]
##str(city.table)
##print(city.table)
names(city.table)[1] <- "city"
p1 <- ggplot(city.table,aes(x=city,y=Freq)) + my.ggplot.theme()+
  geom_bar(fill="turquoise3",stat = "identity") + 
  labs(x="城市",y="不同城市需求占总量的比率",
       title="“上海，深圳，北京，广州，杭州”占据了近90%的需求量,\n是数据分析师的首选") +
  scale_y_continuous(labels = scales::percent)

# group_diff <- diff(range(salary))/20
group_diff <- diff(range(salary))/100
p2 <- p.cn + geom_histogram(aes(x=salary,y=..density..),
                            binwidth = group_diff,fill="turquoise3",color="white")+
  stat_density(geom = "line",position = "identity",
               aes(x=salary),color="brown1")+
  labs(x="年薪(w/年)",
       title="数据分析师平均年薪为18.33w，年薪的分布主要集中在10w~25w之间，\n拿到15w以上的年薪机会比较大") +
  scale_x_continuous(limits = c(0,120)) + scale_y_continuous(limits = c(0,0.04))

multiplot(p1,p2,cols = 1)
```



#### 问题二：不同经验，数据分析岗位的需求分布以及对应的薪资分布

企业对工作经验在2-5年的数据分析师最为热衷，而5-10年甚至更长的数据分析师，一般都去做管理层或者创业了，做的更多是战略性工作。其次随着工作经验的增加数据分析师的薪资收入也在增长。

![1553915070817](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553915070817.png)

代码如下：

```
#问题2：不同经验，数据分析岗位的需求分布以及对应的薪资分布
exp.table <- prop.table(table(experience))
exp.table <- as.data.frame(exp.table)
p3 <- ggplot(exp.table,aes(x=experience,y=Freq)) + my.ggplot.theme()+
  geom_bar(fill="turquoise3",stat = "identity") + 
  labs(x="工作经验",y="不同工作经验需求占总量的比率",
       title="企业需要更有经验的分析师，主要需求\n集中在1-3年和3-5年经验") +
  scale_y_continuous(labels = scales::percent)

p4 <- p.cn + geom_boxplot(aes(x=experience,y=salary),fill="turquoise3")+
  labs(x="工作经验",y="平均月薪(K/月)",
       title="随着工作经验的增加，数据分析师的\n月薪有非常可观的增长")

multiplot(p3,p4,cols = 2)
```



#### 问题三：不同学历，数据分析岗位的需求分布以及对应的薪资分布

90%以上的数据分析岗位要求本科及以上学历，其中仅仅本科就占据了80%。从选取样本种可以看到学历与薪资水平增长的关系不明显。对这里的解释，有两个方面，第一：数据分析相关岗位对工作经验的要求高于学历要求，第二数据量太小不具有代表性

![1553915765087](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553915765087.png)

代码如下

```
#问题3：不同学历，数据分析岗位的需求分布以及对应的薪资分布

edu.table <- prop.table(table(education))
edu.table <- as.data.frame(edu.table)
p5 <- ggplot(edu.table,aes(x=education,y=Freq)) + my.ggplot.theme()+
  geom_bar(fill="turquoise3",stat = "identity") + 
  labs(x="学历",y="不同学历需求占总量的比率",title="超过90%的岗位需要本科及以上的学历") +
  scale_y_continuous(labels = scales::percent)
p6 <- p.cn + geom_boxplot(aes(x=education,y=avg_salary),fill="turquoise3")+
  labs(x="学历",y="月薪(K/月)",
       title="学历与薪资水平增长的关系不明显")
multiplot(p5,p6,cols = 2)
```

#### 问题四：不同企业规模，数据分析岗位的需求分布以及对应的薪资分布

企业规模越大对数据分析相关岗位需求量也越大。但是有意思的是50-150人规模的企业愿意给出更高的薪酬。这里的解释是，对需要快速发展的企业愿意给出高薪，以求取经验能力更高的数据分析师

![1553916256105](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553916256105.png)

代码如下

```
#问题4：不同企业规模，数据分析岗位的各项需求分布及薪资分布

scale.table <- data.frame(prop.table(table(scale)))
p7 <- ggplot(scale.table,aes(x=scale,y=Freq)) + my.ggplot.theme()+
  geom_bar(fill="turquoise3",stat = "identity") + 
  labs(x="企业规模",y="不同企业规模需求占总量的比率",title="接近90%的需求量集中在150人以上\n规模的企业")+
  theme(axis.text.x = element_text(angle = 30,hjust = 1))+
  scale_y_continuous(labels = scales::percent)
p8 <- p.cn + geom_boxplot(aes(x=scale,y=avg_salary),fill="turquoise3")+
  labs(x="企业规模",y="月薪(K/月)",
       title="150人以下规模且需快速发展的企业\n愿意给出更高的薪酬")+
  theme(axis.text.x = element_text(angle = 30,hjust = 1))
multiplot(p7,p8,cols = 2)

```

#### 问题五：探索数据分析岗位对应的工具型技能与对应的薪资水平

数据分析岗位对SQL、SAS、R、Python、Excel工具技能要求最高，其次掌握Spark、Hadoop、Hive、R、Python等工具可以获得更高的片酬。

![1553921800824](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553921800824.png)

![1553916584049](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553916584049.png)

![1553921909132](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553921909132.png)

代码如下

```
#问题5：探索数据分析岗位对工具型技能的需求

#工具型技能分布
key.df <- data.frame(table(reorder_size(merge.df$keyword,TRUE)))
key.df$Freq <- key.df$Freq/length(CN.clean$id)
ggplot(key.df)+my.ggplot.theme() + 
  geom_bar(aes(x=Var1,y=Freq),fill = "turquoise3",stat = "identity") + 
  labs(x="工具型技能",y="不同技能需求占总岗位需求量的比率",
       title="SQL,R,Python,Excel是数据分析师的必备技能，超过78%的岗位都要求掌握SQL，
       \nR语言的需求量居于第二") +
  theme(axis.text.x = element_text(angle = 30,hjust = 1))+
  geom_text(aes(x=Var1,y=Freq,label=paste(round(key.df$Freq,3)*100,'%',sep = '')),vjust=-0.2)+
  scale_y_continuous(labels = scales::percent)


#工具型技能与工作经验的分析
key.exp <- data.frame(prop.table(table(merge.df$keyword,merge.df$experience),2))
names(key.exp)[1:2] <- c("kw","exp")
ggplot(key.exp)+my.ggplot.theme()+
  geom_bar(aes(x=kw,y=Freq,fill=exp),stat = "identity")+
  labs(x="工具型技能",y="比率",fill="工作经验",
       title="工作经验要求越高对BI、EXCEL等office工具的需求越少，
       \n对数据库、Hadoop和Hive等大数据工具的需求越高")+
  facet_grid(exp~.)+
  theme(axis.text.x = element_text(angle = 30,hjust = 1))+
  geom_text(aes(x=kw,y=Freq,label=paste(round(key.exp$Freq,3)*100,'%',sep = '')),vjust=0,size=3)+
  scale_y_continuous(labels = scales::percent)
```



#### 问题六：探索数据分析岗位对应非工具型能力的需求

![1553921923428](C:\Users\RainMan\AppData\Roaming\Typora\typora-user-images\1553921923428.png)

### 总结

1. 从地域来看，北京、深圳、上海、杭州、广州应该是数据分析师的首选城市。
2. 从总体需求来看，企业更加需要具备多年工作经验，且动手能力强、解决实际问题的分析人才，随着工作经验的增加，其对应的薪资也有可观的增长。
3. 从大环境看，自助式分析工具的逐步完善与人工智能技术的突破，也可能使得企业现有业务人员能够上手基础的分析工作，导致企业对经验较低的分析师需求减少。
4. 从企业规模看，150人以上规模的企业更加适合新人进去锻炼，一方面企业已经完成了基本的数据体系架构，且越大的企业数据量级越大，另一方面，企业需要逐步培养强大的数据分析团队来支撑业务的增长。
5. 从分析师个人的角度，则需要更加关注自身成功项目经验的积累，这是升职加薪的必备条件，且需要思考未来自身的发展路径，提前做好准备，相对于业务方向，大数据工程师方向会有更可观的薪资。
6. 从能力的角度，数据分析师需要掌握SQL，Excel，R，Python四个必备的工具（R和Python可以选择其一为主要工具），新人可以注重BI，PPT等office工具的技能，如果是大数据挖掘，越往后则需要更加关注hadoop，Hive，Spark等工具；
7. 数据分析师个人还需要注重逻辑思维、表达沟通、分析报告等关键能力